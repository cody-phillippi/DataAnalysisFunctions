## remove outliers from your df using 
def outlier_removal(df):
    for col in df.columns:
        print("cleaning...",col)
        if (((df[col].dtype)=='float64') | ((df[col].dtype)=='int64')):
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower = Q1 - 1.5 * IQR
            upper = Q3 + 1.5 * IQR
            df = df[df[col].between(lower, upper)]
        else:
            df[col]
    return df

	
	
## use this function to remove outliers based on specific groupings. For example: 
## I used this to remove PG outliers from each offer type group so we could getr an accurate average deal size of each 
## you will need numpy and pandas already imported for this to work

## input your list of items that you are wanting to do grouping wise outlier removal
## input your dataframe
## input the column or columns you are wanting to check for outliers 
## input your grouping / filtering column
## input the name of your output list that you are going to want to store your items in
def grouping_outlier_removal(df, starting_lst, outlier_col, new_lst, filter_col):
 
		## create a list that your outliers are going
		## initialize 
		new_lst = [] 
		
		## create a new unique ID column that we can use to indentify each row (i just used the dataframes index)
		df['tmp_id'] = df.index

		## loop through your list of groupings 
		for i in starting_lst: 
			
			##create a tmp df that we can filter based on without effecting the main filter 
			tmp = df[df.filter_col == i]
			
			## filter tmp column using zscore outlier removal 
			tmp = tmp[(np.abs(stats.zscore(tmp.outlier_col)) > 3)]
			
			##create a tmp list to store all of the unique ids into temporarily 
			tmp_list = tmp.tmp_id.to_list()

			## avoid an NoneType error here 
			## check if the list has any values
			if len(tmp_list) > 0: 
				## add the tmp list items to our master outlier list
				new_lst.extend(tmp_list)
			else: 
				## or else move on

		print("Done!")
    
## Calculate VIF and Standard scaling in one function to help understand multicolinearity
## of dependent vars. Must import StandardScaler lib for this to work
def vif_score(x):
    scaler = StandardScaler()
    arr = scaler.fit_transform(x)
    return pd.DataFrame([[x.columns[i], variance_inflation_factor(arr,i)] for i in range(arr.shape[1])], columns=["FEATURE", "VIF_SCORE"])